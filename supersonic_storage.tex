\documentclass{pracamgr}

\usepackage{polski}
\usepackage[latin2]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{svg}
\usepackage{url}
\usepackage[intlimits]{amsmath}
\widowpenalty=10000
\clubpenalty=10000
% student
\author{Wojciech ¯ó³tak}

\nralbumu{292583}

\title{Wzorowany na PAX trwa³y sk³ad danych dla kolumnowej hurtowni
danych Supersonic}

\tytulang{PAX-like persistent data store for columnar data warehouse Supersonic}


% informacje o pracy
\kierunek{Informatyka}

\opiekun{dr hab. Krzysztofa Stencla\\
Instytut Informatyki}

\date{Sierpieñ 2014}

\dziedzina{11.3 Informatyka}

\klasyfikacja{
H. Information Systems \\
H.2 Database Management \\
H.2.2 Physical Design
}

\keywords{baza danych, metody sk³adowania danych, trwa³y magazyn danych, PAX,
kolumnowo¶æ, metadane}

\newtheorem{defi}{Definicja}[section]


% tresc
\begin{document}
\maketitle

\begin{abstract}
Supersonic jest opracowan± przez firmê Google, kolumnow± hurtowni± danych.
Dziêki wykorzystaniu algorytmów projektowanych z uwzglêdnieniem sposobu
dzia³ania pamiêci podrêcznej procesora, instrukcji SIMD oraz obliczeñ
wektorowych jest w stanie uzyskaæ bardzo wysok± wydajno¶æ. Niestety, obecnie nie
udostêpnia ¿adnego mechanizmu pozwalaj±cego przechowywaæ dane.

W pracy opracowano oraz zaimplementowano mechanizmy trwa³ego sk³adowania danych
wzorowane ne schemacie PAX. W trakcie fazy projektowania uwzglêdniono
przeznaczenie do pracy w ¶rodowisku hurtowni danych. Wytworzona implementacja
zosta³a przeanalizowana pod k±tem wydajno¶ci operacji zapisu i odczytu, a tak¿e
porównana ze sk³adami popularnych systemów bazodanowych - \textit{MySQL} oraz
\textit{PostgreSQL}. Wykorzystano przy tym dane pochodz±ce z testu porównawczego
\textit{TPC-H}. Ewaluacja wykaza³a, ¿e proponowane rozwi±zanie dobrze sprawdza
siê w praktyce.
\end{abstract}

\tableofcontents

%
% Wprowadzenie
%
\chapter{Wprowadzenie}

\section{Supersonic jako kolumnowy wykonawca zapytañ}
Kolumnowe bazy danych nie s± nowym pomys³em. Pierwsze aplikacje organizuj±ce
przetwarzane dane wed³ug kolumn powsta³y ju¿ pod koniec lat siedemdziesi±tych XX
wieku\cite{taxir}. Na przestrzeni lat okaza³o siê, ¿e koncept ma praktyczne
zastosowanie w hurtowniach danych oraz systemach wspomagania decyzji. Ze wzglêdu
na efektywne wykorzystanie pamiêci podrêcznej procesora\cite{bonch-cache} oraz
operacji wektorowych\cite{bonch-pipe} mo¿liwe jest osi±gniêcie znacznie wiêkszej
wydajno¶ci w zapytaniach wymagaj±cych przetworzenia du¿ych ilo¶ci danych. \\

Supersonic\cite{supersonic} jest wysokowydajnym, kolumnowym wykonawc± zapytañ
wyprodukowanym przez firmê Google i udostêpnionym na zasadach wolnego
oprogramowania w pa¼dzierniku 2012 roku. Cechuje go ¶wiadome wykorzystywanie
funkcji nowoczesnych procesorów - pamiêci podrêcznej, potokowania, instrukcji
SIMD oraz efektywne zarz±dzanie pamiêci±. Jest te¿ dobrze przetestowany i
stabilny. Umo¿liwia wykonanie wiêkszo¶ci typowych operacji bazodanowych
(selekcja, projekcja, z³±czenia, agregacja), a tak¿e wyra¿eñ matematycznych,
operacji na datach i ci±gach znaków. \\

Niestety, Supersonic jest w chwili obecnej wy³±cznie wykonawca zapytañ i nie
udostêpnia wielu funkcjonalno¶ci oczekiwanych od systemów bazodanowych. Nie
obs³uguje ¿adnego jêzyka zapytañ - drzewo algebry relacji musi byæ konstruowane
rêcznie przez programistê. Nie istniej± optymalizatory zapytañ. Nie udostêpnia
tak¿e ¿adnego interfejsu umo¿liwiaj±cego trwa³e magazynowanie danych (choæby w
formie plików na dysku). Wszystko to znacznie utrudnia korzystanie z
Supersonica zwyk³emu u¿ytkownikowi i znacznie ogranicza grupê potencjalnych
odbiorców.

\section{¦rodowisko hurtowni danych}

Supersonic, ze wzglêdu na swoj± kolumnow± naturê, przeznaczony jest do pracy w
¶rodowiskach typowych dla hurtownii danych. Obliczane w nich zapytania
zazwyczaj maj± do¶æ specyficzn± postaæ:
\begin{itemize}
  \item{Przewa¿nie operuj± na naprawdê du¿ych tabelach - zawieraj±cych wiele
giga-, tera- czy nawet petabajtów danych.}
  \item{Nie odnosz± siê do pojedynczych rekordów (np. dotycz±cych konkretnego
u¿ytkownika), a raczej wiêkszych zakresów danych czy wrêcz kompletnych tabel.}
  \item{Czêsto odnosz± siê do stosunkowo niewielkiego podzbiorach atrybutów
relacji, zw³aszcza w przypadku tabel posiadaj±cych dziesi±tki czy setki kolumn.}
  \item{Odczyt danych jest operacj± znacznie czêstsz± ni¿ zapis.}
\end{itemize}
Efektywne przetworzenie takiej ilo¶ci danych wymaga zrównoleglenia obliczeñ na
wiele maszyn, a w konsekwencji wykorzystanie rozproszonych systemów plików
takich jak na przyk³ad \textit{HDFS}\cite{hdfs}. Systemy takie cechuje czêsto
brak mo¿liwo¶ci zapisu swobodnego, a jedynie dopisywanie danych na koñcu pliku.
Ponadto, w ¶rodowisku takim wa¿nym zasobem jest sieæ. Redukcja ilo¶ci danych,
które trzeba przez ni± przes³aæ mo¿e mieæ du¿y wp³yw na wydajno¶æ obliczenia.


\section{Zakres pracy}

Celem niniejszej pracy magisterskiej by³o zaprojektowanie, zaimplementowanie i
zbadanie zachowania sk³adu danych dla wykonawcy zapytañ Supersonic
przystosowanego do pracy w opisanym wcze¶niej ¶rodowisku. \\

Temat efektywnego sk³adowania danych relacyjnych by³ szeroko poruszany w
literaturze\cite{nsm} i wielu publikacjach
naukowych\cite{dsm,pax,column-vs-row}. Przyk³adowe sposoby przechowywania takich
danych opisane s± w drugim rozdziale pracy. Znajduj± siê tam równie¿ informacje
dotycz±ce ró¿nych metod kompresji oraz wykorzystania metadanych w celu
zwiêkszenia efektywno¶ci magazynu. \\

Rozdzia³ trzeci zawiera szczegó³owy opis rozwi±zania oraz jego implementacji.
Proponowany magazyn ³±czy w sobie wiele rozwi±zañ znanych z istniej±cych
systemów, m.in. organizacjê danych na stronach w schemacie \textit{PAX}
(\textit{Partition Attributes Across}), grupowanie atrybutów w rodziny
(stosowane np. w BigTable\cite{bigtable}) czy zastosowanie metadanych oraz
indeksów. \\

W rozdziale czwartym opisane zosta³y do¶wiadczenia wykonane na magazynie w celu
zbadania jego zachowania podczas pracy. Wykorzystano do tego dane pochodz±ce z
testu porównawczego \textit{TPC-H}\cite{tpch}, bêd±cego standardem przemys³owym
w zakresie badania wydajno¶ci systemów bazodanowych. W celu umieszczenia
wyników w szerszym kontek¶cie, czê¶æ z testów zosta³a wykonan równie¿ na
innych, popularnych systemach bazodanowych: \textit{MySQL} oraz
\textit{PostrgreSQL}. Zestawienie tych rezultatów pozwala oceniæ jak dobrze
zachowuje siê proponowane rozwi±zanie w porównaniu z ju¿ istniej±cymi
magazynami, w kontek¶cie zastosowania w hurtowniach danych. \\


\section{Za³o¿enia dotycz±ce rozwi±zania}

Maj±c na uwadzê specyfikê ¶rodowiska pracy w hurtowni danych, w którym ma
funkcjonowaæ projektowany magazyn, sformu³owane zosta³y pewne za³o¿enia
dotycz±ce oczekiwanego rozwi±zania.

\subsubsection{Format magazynu na no¶niku}

Zapis danych na no¶nik powinien generowaæ seriê fizycznych plików o
ograniczonym rozmiarze. Pliki te powinny same w sobie stanowiæ niezale¿ne
magazyny, co umo¿liwi ich równoleg³e przetwarzanie np. w ¶rodowisku
rozproszonym. \\

Analogicznie, odczyt zapisanych danych powinien byæ mo¿liwy z serii plików.
Pliki zawieraj±ce relacja o takim samym zbiorze atrybutów powinny byæ ze sob±
kompatybilne niezale¿nie od tego kiedy zosta³y zapisane (np. pliki pochodz±ce z
dwóch ró¿nych zapytañ).

\subsubsection{Odczyt jako podstawowa operacja}

Mo¿na za³o¿yæ, ¿e odczyt jest podstawow± operacj± i musi byæ wykonywany mo¿liwie
efektywnie. W szczególno¶ci, oznacza to, ¿e:
\begin{itemize}
  \item{Prêdko¶æ zapisu jest spraw± drugorzêdn±. W szczególno¶ci, czas
po¶wiêcony na przyk³ad na wyliczenie i utrwalenie metadatanych pozwalaj±cych na
optymalizacjê operacji odczytu nie jest czasem straconym.}
  \item{Nie jest wymagana mo¿liwo¶æ modyfikacji istniej±cych plików magazynu. W
razie potrzeby mo¿na przeczytaæ i przetworzyæ dane, a nastêpnie zapisaæ w nowej
lokalizacji.}
\end{itemize}
Szczególna uwaga powinna zostaæ po¶wiêcona efektywnemu odczytywaniu podzbioru
atrybutów, co mo¿e mieæ bardzo du¿y wp³yw na liczbê, które trzeba przes³aæ
miêdzy sk³adem a aplikacj± obliczaj±c± wynik zapytania.

\subsubsection{Obs³uga ró¿nych systemów plików i no¶ników danych}

W celu u³atwienia wdro¿enia magazynu w istniej±cych ¶rodowiskach powinna istnieæ
mo¿liwo¶æ obs³ugi ró¿nych systemów plików i no¶ników danych, np.:
\begin{itemize}
  \item{urz±dzeñ blokowych,}
  \item{systemów plików zgodnych z \textit{VFS} (interfejsem ujednolicaj±cym
dostêp do plików, np. w systamach Linux),}
  \item{wyspecjalizowanych, rozproszonych systemów plików, takich jak
\textit{HDFS}.}
\end{itemize}


%
% Sposoby sk³adowania danych
%
\chapter{Sposoby sk³adowania danych}

\section{Logiczna i fizyczna warstwa sk³adu danych}

W ka¿dym sk³adzie danych mo¿na wyró¿niæ dwie podstawowe warstwy:

\begin{itemize}
  \item{\textbf{fizyczn±} - obejmuj±c± sposób w jaki dany zorganizowane s± w
    systemie plików czy na urz±dzeniu blokowym.}
  \item{\textbf{logiczn±} - obejmuj±c± logiczne struktury danych, pozwalaj±ce
    na manipulacjê danymi przez aplikacjê bez ¶wiadomo¶ci faktycznej
    organizacji danych na no¶niku.}
\end{itemize}

Obecnie, ze wzglêdu na coraz popularniejsze wykorzystanie rozproszonych systemów
plików oraz maszyn wirtualnych, granica miêdzy fizyczn± i logiczn± warstw±
zaciera siê. Pod abstrakcyjnym interfejsem umo¿liwiaj±cym dostêp do pliku, czy
urz±dzenia mo¿e kryæ siê nie fizyczny sprzêt lecz skomplikowana logika.


\subsection{Warstwa fizyczna}

Na poziomie warstwy fizycznej dane mog± byæ zorganizowane na ró¿ne sposoby:

\begin{itemize}
  \item{W systemie plików systemu operacyjnego, jako jeden b±d¼ wiêcej plików.
U³atwia to zarz±dzanie danymi, przenoszenie ich miêdzy no¶nikami itp.  Jest to
najczê¶ciej spotykane rozwi±zanie w popularnych systemach bazodanowych.}
  \item{Bezpo¶rednio na partycji, z pominiêciem systemu plików (np. dostêpne
jako opcja w Oracle).  Umo¿liwia to bezpo¶redni dostêp do urz±dzenia i rêczne
zarz±dzanie buforowaniem danych, co w pewnych przypadkach mo¿e skutkowaæ
zwiêkszeniem wydajno¶ci. \\
Obecnie, wiele systemów plików pozwala na dostêp do urz±dzenia z pominiêciem
pamiêci podrêcznych, daj±c aplikacjom wiêksz± kontrolê nad operacjami
wej¶cia/wyj¶cia. Z tego powodu rozwi±zanie to jest znacznie rzadziej stosowane.}
\end{itemize}

Pliki w warstwie fizycznej sk³adaj± siê z \textit{bloków} (udostêpniane przez
tzw. \textit{urz±dzenia blokowe}). S± to struktury na poziomie systemu
operacyjnego, okre¶laj±ce najmniejsz± jednostkê danych, które mo¿na
odczytaæ/zapisaæ. Nie nale¿y ich myliæ z \textit{blokami danych} (zwanymi te¿
\textit{stronami}) z warstwy logicznej. Relacja miêdzy tymi dwoma rodzajami
bloków mo¿e, lecz nie musi istnieæ i mieæ wp³yw na wydajno¶æ operacji
wej¶cia/wyj¶cia wewn±trz aplikacji. Nale¿y równie¿ podkre¶liæ, ¿e owe
\textit{strony danych} to pojêcia zupe³nie inne ni¿ \textit{strony pamiêci}
systemu operacyjnego i nie musz± mieæ ze sob± nic wspólnego.
 

\subsection{Warstwa logiczna}

Podstawow± jednostk± organizacji danych jest \textit{blok danych} nazywany tak¿e
\textit{stron±} (w dalszej czê¶ci pracy u¿ywaæ bêdziemy tej drugiej nazwy, w
celu odró¿nienia od bloków systemu operacyjnego). Znajduj± siê one na styku
warstwy logicznej i fizycznej. Z jednej strony udostêpniaj± abstrakcyjny
interfejs dostêpu do danych, z drugiej posiadaj± konkretn±, fizyczn±
organizacjê, maj±c± wielki wp³yw na pracê systemu. \\

Strony czêsto organizowane s± w wiêksze struktury np. reprezentuj±ce poszczególne
tablice bazy danych, zarz±dzane i interpretowane przez kolejne czê¶ci warstwy
logicznej. Ich konstrukcja w du¿ej mierze zale¿y od sposobu w jaki baza danych
przetwarza zapytania.


\section{Fizyczna organizacja danych w stronach}

Jak pokazuj± badania, sposób fizycznego zorganizowania danych w obrêbie strony
mo¿e mieæ bardzo istotny wp³yw na wydajno¶æ. Jest to zwi±zane z ró¿nymi
aspektami pracy systemu bazodanowego, m.in.:

\begin{itemize}
  \item{przepustowo¶ci± zapisu oraz odczytu medium, na którym sk³adowane s±
dane},
  \item{liczb± operacji wej¶cia/wyj¶cia niezbêdnych do realizacji zapytania (ze
szczególnym uwzglêdnieniem operacji wymuszaj±cych przesuniêcia g³owicy, w
przypadku dysków HDD),}
  \item{efektywnym wykorzystaniem pamiêci podrêcznych procesora,}
  \item{kosztem \textit{materializacji krotek}, czyli rekonstrukcji relacji w
    formie umo¿liwiaj±cej dostêp do wierszy.}
\end{itemize}

W zale¿no¶ci od konstrukcji wykonawcy zapytañ, dostêp do danych mo¿e odbywaæ siê
poprzez przekazywanie fragmentów poszczególnych kolumn, b±d¼ poszczególnych
rekordów. Warto zauwa¿yæ, ¿e kszta³t interfejsu nie musi determinowaæ
implementacji i mo¿na przyk³adowo wykorzystywaæ wierszowo zorientowane strone
implementuj±c interfejs kolumnowy. Istniej± jednak badania pokazuj±ce, ¿e
takie sztuczne symulowanie odmiennej organizacji nie pozwala uzyskaæ tak
dobrych wyników jak w pe³ni spójny system.\cite{column-vs-row} \\


\subsection{Przyk³ady organizacji stron danych}

Jako przyk³ad omówiê trzy, czêsto poruszane w literaturze, sposoby organizacji
danych w obrêbie stron:

\subsubsection{NSM}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{images/NSM.pdf}
  \caption{Organizacja danych na stronie NSM}
\end{figure}

W NSM (\textit{N-ary Storage Model}) dane relacji zapisywane s± sekwencyjnie, w
obrêbie strony. Ka¿dy rekord posiada nag³ówek zawieraj±cy maskê bitow± mówi±c± o
istnieniu danych (przy obs³udze warto¶ci \textit{NULL}), pozycje atrybutów
zmiennej d³ugo¶ci oraz dane zwi±zane z implementacj±. Ze wzglêdu na zmienn±
d³ugo¶æ rekordów na koñcu strony utrzymywany jest indeks, utrzymuj±cy pozycje
kolejnych wpisów w obrêbie strony. \\

Zalet± takiej organizacji danych jest wysoka lokalno¶æ wierszy relacji,
pozwalaj±ca na odczyt wymaganych rekordów przy mo¿liwie niskiej liczbie operacji
odczytu i przesuniêcia w obrêbie pliku. Problemy pojawiaj± siê w przypadku gdy w
zapytaniu bierze udzia³ tylko niewielki podzbiór kolumn. Strony danych
odczytywane s± zawsze w ca³o¶ci, co w przypadku NSM oznacza ci±gi kompletnych
rekordów. W momencie gdy zapytanie dotyczy wy³±cznie u³amka atrybutów wiêkszo¶æ
pobranych danych jest zupe³nie nieprzydatna. Nieefektywne wykorzystanie magazynu
i marnowanie przepustowo¶ci medium dramatycznie pogarsza wydajno¶æ systemu
bazodanowego. \\

Z tego samego powodu NSM mo¿e mieæ negatywny wp³yw na efektywno¶æ pamiêci
podrêcznej procesora. Dane do niej pobierane s± zawsze ci±g³ymi przedzia³ami. W
momencie gdy interesuj± nas tylko niektóre atrybuty z ca³ego wiersza tabeli mo¿e
siê okazaæ, ¿e interesuj±cych danych mie¶ci siê bardzo ma³o i trzeba czêsto
odwo³ywaæ siê do kolejnych warstw pamiêci, cechuj±cych siê coraz wiêkszymi
opó¼nieniami. Warto przy tym wspomnieæ, ¿e obecnie typowa \text{linia pamiêci
podrêcznej} L1 (a wiêc najmniejsza jednostka danych wymieniana miêdzy warstwami
pamiêci) liczy sobie 64 bajty. Do jej wype³nienia wystarczy wiêc krotka
zawieraj±ca szesna¶cie 32-bitowych liczb ca³kowitych czy np. pojedynczy hasz md5
w formie tekstowej.
 
\subsubsection{DSM}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{images/DSM.pdf}
  \caption{Organizacja danych na stronach DSM}
\end{figure}

DSM (\textit{Decomposition Storage Model}) by³o prób± odpowiedzi na problemy
NSM z pamiêci± podrêczn± i zbêdnymi operacjami wej¶cia/wyj¶cia w przypadku
pracy na podzbiorze atrybutów relacji. Idea opiera siê na rozbiciu relacji na
\textit{podrelacje} z³o¿one z dwóch atrybutów - identyfikatora rekordu oraz
pojedynczej kolumny relacji. Identyfikator jest sztucznym atrybutem u¿ywanym
wy³±cznie do materializacji relacji na potrzeby obliczenia, czêsto nie jest
nawet fizycznie utrzymywany, a jedynie wyliczany w locie na podstawie pozycji
rekordu w stronie. Zamiast w nag³ówkach informacje o warto¶ciach \textit{NULL}
przechowywane s± w tablicy na koñcu strony. W przypadku typów zmiennej d³ugo¶ci
znajduj± siê tam równie¿ wska¼niki do odpowiednich pozycji. \\

Schemat ten cechuje siê wysok± lokalno¶ci± danych w obrêbie kolumny i w zasadzie
rozwi±zuje przedstawione wy¿ej problemy. Rodzi jednak nowe, zwi±zane z
materializacj± relacji. Rekonstrukcja wierszy z³o¿onych z $N$ kolumn wymaga
dokonania z³±czenia na $N$ podrelacjach. Koszt takiej operacji ro¶nie wraz z
liczb± atrybutów, a¿ w koñcu staje siê dominuj±cy. Niektóre bazy danych
(najczê¶ciej kolumnowe) stosuj± technikê zwan± \textit{pó¼n±
materializacj±}\cite{materialization}, która w pewnym stopniu redukuje problem.
Polega ona na operowaniu na pojedynczych kolumnach relacji tak d³ugo jak to
mo¿liwe i odroczeniu materializacji. Zachowanie to mo¿e zmniejszaæ liczbê 
rekordów, które s± rekonstruowane (np. z powodu zaaplikowanej wcze¶niej
selekcji). Ponadto, operowanie na pojedynczych kolumnach pozwala na
efektywniejsze wykorzystanie pamiêci podrêcznej i schematów lekkiej kompresji.
\\

Dodatkowy problem stanowi niska lokalno¶æ wierszy relacji. Dostêp do
pojedynczych rekordów mo¿e wymagaæ odczytania wielu stron, co jest kosztowne. Z
tego powodu rozwiazanie takie ¼le sprawuje siê w systemach typu OLTP
(\textit{Online Transaction Processing}) cechuj±cych siê zapytaniami
odwo³uj±cymi siê do ma³ej liczby (a czêsto nawet pojedynczych) rekordów. Problem
sprawiaj± równie¿ przeszukiwania za pomoc± indeksów, które dokonuj± du¿ej ilo¶ci
skoków w obrêbie danych. \\

Generalnie, mamy wiêc do czynienia z charakterystyk± odwrotn± ni¿ w przypadku PAX
- efektywnym wykorzystaniem pasma dysku poprzez pobieranie wy³±cznie niezbêdnych
danych oraz wiêksz± ilo¶ci± przesuniêæ g³owicy potrzebnych do rekonstrukcji
pojedynczych wierszy.


\subsubsection{PAX}

PAX (Partition Attributes Across) jest prób± po³±czenia zalet NSM i DSM. Pomys³
polega na sekwencyjnym zapisie stron zawieraj±cych zbiór rekordów, tak jak w
NSM, lecz z wewnêtrzn± organizacj± kolumnow±, tak jak w DSM. Rozwi±zanie takie
sprawia, ¿e lokalno¶æ danych zarówno na poziomie wierszy jak i kolumn jest do¶æ
wysoka. Poniewa¿ dane wewn±trz strony stanowi± spójn± i niezale¿n± ca³o¶æ
materializacja relacji mo¿e byæ wykonana w bardzo efektywny sposób. To z kolei
pozwala na efektywne wykorzystanie pamiêci podrêcznej podczas pracy na
podzbiorze kolumn. Niestety, nie rozwi±zuje to problemu na poziomie odczytu
danych z no¶nika - zawsze pobierane s± wszystkie atrybuty relacji, a
konsekwencji marnuje siê pasmo medium.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{images/PAX.pdf}
  \caption{Organizacja danych na stronie PAX}
\end{figure}

Jak pokazuj± badania\cite{pax}, rozwi±zanie takie jest swego rodzaju kompromisem
i w skrajnych przypadkach zachowuje siê nieco gorzej ni¿ NSM i DSM. Ró¿nica ta
jest jednak niewielka. W zamian PAX oferuje du¿o wiêksz± elastyczno¶æ i
stabilny koszt dla ró¿nego rodzaju zapytañ. Ilo¶æ operacji wej¶cia/wyj¶cia jest
porównywalna z NSM, natomiast efektywne wykorzystanie pamiêci podrêcznej
pozwala na redukcjê pustych cykli procesora (nawet o 70-75\%), rekompensuj±c
straty zwi±zane z potrzeb± ewentualnej materializacji wierszy. Je¶li za³o¿ymy,
¿e w typowym przypadku system bazodanowy musi wykonywaæ wiele ró¿nych typów
zapytañ (np. zarówno agregacje pojedynczych atrybutów, jak i selekcje pe³nych
wierszy) PAX jest dobrym rozwi±zaniem. \\



\subsection{Rozwój procesorów a organizacja danych na stronie}

Warto przy okazji wspomnieæ, ¿e od pewnego czasu rozwój centralnych jednostek
obliczeniowych nie jest zwi±zany ze zwiêkszaniem taktowania (ju¿ w 2005 roku
dostêpne by³y procesory Pentium 4 3.8GHz, które, przy zastosowaniu odpowiedniego
ch³odzenia, mog³y dzia³aæ stabilnie nawet przy taktowaniu 5GHz), a wiêc liczb± 
instrukcji, które mog± zostaæ wykonane na sekundê. Zamiast tego istotne jest
wykorzystanie wielu rdzeni oraz redukcja pustych cykli procesora zwi±zanych np.
z hazardem danych i sterowania, potokowaniem, czy opó¼nieniami w dostêpie do
pamiêci RAM. Pamiêæ podrêczna odgrywa tutaj bardzo wa¿n± rolê, przez co jej
efektywne wykorzystywanie bywa kluczowe przy pisaniu wydajnych aplikacji. Wobec
tego PAX wydaje byæ najbardziej przysz³o¶ciowym schematem organizacji danych
spo¶ród przedstawionych.


\section{Kompresja danych}

Zagadanienie wykorzystania kompresji w systemach bazodanowych jest bardzo
obszerne i mog³oby stanowiæ g³ówny temat oddzielnego opracowania. Omawiane w
pracy rozwi±zanie nie implementuje ¿adnych metod kompresji danych. Jest to
jednak temat na tyle istotny w kontek¶cie sk³adowania danych, ¿e nie sposób o
nim nie wspomnieæ.

\subsection{Cele i wymagania stawiane przed kompresj± danych}

Podstawowym celem kompresji danych jest zmniejszenie ich objêto¶ci, a co za tym
idzie, zwiêkszenie przepustowo¶ci przep³ywu danych pomiêdzy pamiêci± operacyjn±
a urz±dzeniem. Dodatkowo, w przypadku systemów rozproszonych, pozwala to
oszczêdniejsze wykorzystanie transferu sieciowego, bêd±cego czêsto cennym i
mocno ograniczonym zasobem. \\

Rzecz jasna, kompresja kosztuje czas procesora. W zwi±zku z tym, wymaga siê od
niej odpowiedniej wydajno¶ci. W ogólno¶ci, koszt (de)kompresji nie mo¿e byæ
wiêkszy ni¿ zysk wynikaj±cy z mniejszej liczby odwo³añ do medium przechowuj±cego
dane. Oznacza to, ¿e najbardziej efektywne pod wzglêdem redukcji objêto¶ci
schematy wcale nie musz± dawaæ dobrych rezultatów w zastosowaniu wewn±trz
sk³adów danych. Dobór odpowiedniej metody jest kluczowym aspektem wykorzystania
kompresji w systemie bazodanowym. Du¿± rolê odgrywa tu te¿ konkretna, fizyczna
organizacja danych na stronach. Przyk³adowo, dane w obrêbie kolumn s±
homogeniczne, w zwi±zku z czym bardziej podatne na kompresjê. Wobec tego
schematy takie jak PAX czy DSM uzyskuj± tu pewn± przewagê. \\

\subsection{Rodzaje kompresji danych}

Algorytmy kompresji danych mo¿na podzieliæ na wiele ró¿nych sposobów. Jednym z
bardziej interesuj±cych, w kontek¶cie kolumnowych baz danych, jest podzia³ ze
wzglêdu na koszt obliczeniowy:

\begin{itemize}
  \item{\textbf{algorytmy ciê¿kie} - szeroko stosowane w aplikacjach i
      systemach operacyjnych. Skompresowane dane cechuj± siê zazwyczaj wysokim
      wspó³czynnikiem kompresji, za co p³aci siê znacznym czasem potrzebnym na
      jej wykonanie. Dodatkowo, czêsto algorytmy takie s± blokowe, co oznacza,
      ¿e dostêp do nawet niewielkiej porcji danych wymaga dekompresji du¿ego,
      spójnego fragmentu. Przyk³adem takiego algorytmu jest \textit{gzip} czy
      \textit{lzma}}
  \item{\textbf{algorytmy lekkie} - przydatne w bardzo specyficznych
      zastosowaniach (w tym, w bazach danych). Cechuj± siê niezwykle niskim
      kosztem obliczeniowym i gorszymi wspó³czynnikami kompresji ni¿
      algorytmy ciê¿kie. Zazwyczaj, od strony algorytmicznej, s± wrêcz
      trywialne i mo¿e siê wydawaæ, ¿e nieprzydatne. Istniej± jednak
      badania\cite{light-compression} pokazuj±ce, ¿e w³a¶ciwie zastosowane
      mog± dawaæ bardzo dobre wyniki (np. dziêki efektywnemu wykorzystaniu
      pamiêci podrêcznej procesora). Czêsto umo¿liwaj± praktycznie losowy
      dostêp do danych, bez potrzeby dokompresji wiêkszego kontekstu, a tak¿e
      operowanie bezpo¶rednio na skompresowanych danych.
      Przyk³adem takiej kompresji jest \textit{Run-Lenght Encoding}
      (RLE)} czy \textit{prefix-supression} (PS).
\end{itemize}

Istniej± tak¿e schematy kompresji, trudne do sklasyfikowania, bêd±ce na
pograniczu kompresji lekkiej i ciê¿kiej.  Przyk³ad stanowiæ mog±
\textit{Snappy}\cite{snappy} oraz \textit{LZ4}\cite{lz4}. S± to algorytmy
blokowe, przypominaj±ce klasyczne, ciê¿kie rozwi±zania. Jednak¿e, zamiast na
wysokich wspó³czynnikach kompresji skupiaj± siê na prêdko¶ci dekompresji. Maj±
one zastosowania w ¶rodowiskach, w których zysk wynikaj±cy ze zmniejszonej
objêto¶ci danych mo¿e zostaæ ³atwo zdominowany przez koszt wynikaj±cy z odczytu,
np. protoko³ach serializacji danych (np.  \textit{Apache Avro}) oraz bazach
danych (\textit{HBase}).


\subsection{Przyk³ady lekkiej kompresji danych}

Lekka kompresja jest bardzo ciekawym i stosunkowo ma³o znanym zagadnieniem. W
zwi±zku z tym warto przybli¿yæ kilka przyk³adowych algorytmów, daj±cych ogólne
pojêcie o konstrukcji takich rozwi±zañ. 

\subsubsection{Run-Length Encoding}

Polega na zliczaniu d³ugo¶ci sekwencji powtórzeñ elementów i zapisywania ich
jako pary \textit{(element, liczba)}. Przyk³adowo, sekwencja znaków \texttt{a w w
z z z z z d d d e f f} reprezentuje sekwencja par \texttt{(a,1) (w,2) (z,5)
(d,3) (e,1) (f,2)}. W zale¿no¶ci od rozk³adu elementów uzyskaæ mo¿na ró¿n±
efektywno¶æ kompresji (tak¿e negatywn±), w zwi±zku z czym mo¿na jej stosowaæ w
ka¿dym przypadku.  Warto zauwa¿yæ, ¿e wiele operacji (np. arytmetycznych) mo¿na
wykonywaæ bezpo¶rednio na elementach bez potrzeby rekonstrukcji pierwotnych
danych.

\subsubsection{Prefix-Suppression}

Usuwa wspólny prefiks z warto¶ci. Zwykle jest stosowana do usuwania wiod±cych
zer z zapisu binarnego liczb. Na przyk³ad ci±g liczb reprezentowany przez
\texttt{00001010 00000110 00000001} mo¿e byæ zapisany jako \texttt{1010 0110
0001}. Ma wiêc szczególne zastosowanie w przypadku liczb, bêd±cych istotnie
mniejszymi od maksymalnych warto¶ci z danego typu. Ma on równie¿ zastosowanie
podczas kompresji posortowanych ciagów znaków. Dobrym przyk³adem s± indeksy
adresów URL gdzie wszystkie wpisy dle pojedynczej domeny posiadaj± wspólny
prefiks.

\subsubsection{Frame-Of-Reference}

Dla danego bloku numerycznych warto¶ci znajduje namniejsz± warto¶æ $min$, a
nastêpnie zapisuje ka¿d± warto¶æ $v[i]$ jako $v[i] - min$ korzystaj±c z
\textit{Prefix-Suppresion}. Schemat ten dobrze stosuje siê sklastrowanych
danych, zawieraj±cych warto¶ci stosunkowo bliskie siebie.


\section{Metadane}

Poza przechowywaniem danych samych w sobie bardzo istotne jest przechowywanie
dodatkowych informacji o nich, zwanych \textit{metadanymi}. Mog± byæ one
przeró¿nego rodzaju:

\begin{itemize}
  \item{\textbf{Schemat tabeli} - opisuj±cy nazwê, typ i inne mo¿liwe cechy
ka¿dego z atrybutów.}
  \item{\textbf{Statystyki} dotycz±ce wielu
aspektów\cite{oracle-stats,postgres-stats,mongo-stats}:
    \begin{itemize}
      \item{\textbf{tabel} - liczba wierszy, stron danych, ¶redni rozmiar
krotki, rozmiar na dysku;}
      \item{\textbf{kolumn i stron} - liczba unikalnych warto¶ci, procent
warto¶ci \textit{NULL}, rozk³ady warto¶ci;}
      \item{\textbf{indeksów} - rozmiar, liczba bloków-li¶ci, poziomów w drzewie,
wspó³czynnik sklastorwania danych;}
      \item{\textbf{dzia³ania systemu} - liczba wykonywanych operacji
wej¶cia/wyj¶cia, zu¿ycie zasobów systemowych.}
    \end{itemize}
  }
  \item{\textbf{Wyspecjalizowane struktury} takie jak indeksy i \textit{filtry
Blooma}\cite{bigtable,cassandra}.}
\end{itemize}

Metadane mog± byæ generowane w ró¿nych momentach ¿ycia systemu bazodanowego, w
zale¿no¶ci od projektu, konfiguracji oraz rodzaju. Czê¶æ z nich, np. liczba 
wierszy w tabli, da siê uzyskaæ jako efekt uboczny wykonywania zapytañ.
Niestety wiele przydatnych statystyk, takich jak rozk³ad warto¶ci (histogram) w
wybranej kolumnie, wymaga sporego narzutu obliczeniowego, który móg³by mieæ
istotny wp³yw na prêdko¶æ wykonywania zapytañ. W zwi±zku z tym, czêsto stosuje
siê rozwi±zanie, w którym szczegó³owe informacje wyliczane s± na ¿±danie, przez
oddzielny proces.

\subsubsection{Zysk p³yn±cy z metadanych}

Posiadanie aktuanych metadanych mo¿e mieæ bardzo du¿y wp³yw na wydajno¶æ
systemu bazodanowego. Na ich podstawie mo¿na czêsto podj±æ decyzjê czy wybrana
strona zawiera dane interesuj±ce z perspektywy zapytania - np. przez
odpytanie \textit{filtru Blooma} albo sprawdzenie czy warto¶ci mieszcz± siê
w zadanym przedziale. Blok taki nie ma wp³ywu na wynik obliczenia i mo¿e zostaæ
pominiêty, co w prosty sposób przek³ada siê na skrócenie czasu wykonania
zapytania. Podobnie sprawa ma siê z indeksami, które czêsto pozwalaj± bardzo
dok³adnie okre¶liæ zbiór stron (a czasami nawet konkretnych rekordów w nich
zawartych) bior±cych czynny udzia³ w obliczeniu. \\

Statystyki s± tak¿e cenn± informacj± dla optymalizatora zapytañ. Rozmiar tabel,
rozk³ad warto¶ci, oczekiwana selektywno¶æ filtrów - wszystko to mo¿na
wykorzystaæ w modelu kosztowym w celu oszacowania zasobów potrzebnych do
wykonania konkretnego planu zapytania. Dziêki temu, optymalizator jest w stanie
np. dobraæ algorytm z³±czeñ, czy zmieniæ kolejno¶æ operacji w drzewie algebry
zapytania tak by obliczenie odbywa³o siê w baradziej efektywny sposób. 

\subsubsection{Miejsce i sposób przechowywania}

Metadane w postaci statystyk zajmuj± stosunkowo niewiele miejsca w stosunku do
danych, które opisuj±. Mimo to warto przechowywaæ je w przemy¶lany sposób.
Konkretny format powinien zale¿eæ w g³ównej mierze od celu w jakim gromadzimy
wybrane statystki, tak by da³o siê z nich korzystaæ mo¿liwie ma³ym kosztem.
Przyk³adowo, metadane bloków trzymaæ mo¿emy w kolejno¶ci ich wystêpowania na
dysku, tak by iteruj±c siê po nich znajdowaæ interesuj±ce strony w porz±dku
optymalnym z perspektywy odczytu z urz±dzenia blokowego. \\

Miejsce, w którym przechowuje siê metadatane równie¿ zale¿y od konkretnego
przypadku. Przyk³adowo, mog± to byæ:
\begin{itemize}
  \item{Wydzielone strony danych w pliku z danymi tabeli\cite{sqlite-format}.}
  \item{Osobne, wyspecjalizowane pliki.\cite{oracle-data-files}}
  \item{Oddzielne serwery zarz±dzaj±ce metadanymi, bêd±ce w istocie same w
sobie bazami danych, które mo¿na odpytaæ o ró¿ne informacje dotycz±ce tabel
oraz zbiór stron spe³niaj±cych wiêzy narzucone na zapytanie. Zwykle stosuje siê
je w przypadku rozwi±zañ rozproszonych, zawieraj±cych wiele wêz³ów z
danymi\cite{hbase-region-server}.}
\end{itemize}


%
% Konstrukcja magazynu danych
%
\chapter{Konstrukcja magazynu danych}

\section{Koncepcja sk³adu}

\subsection{Rodziny atrybutów}

Jednym z wyzwañ stoj±cych przed projektowanym magazynem danych by³o
umo¿liwienie wydajnej obs³ugi tablic posiadaj±cych setki, a nawet tysi±ce
kolumn w przypadku zapytañ odnosz±cych siê do ich niewielkiego podzbioru.
Przechowywanie kompletnych krotek relacji w pojedynczych stronach danych
powodowa³oby odczyt wszystkich atrybutów niezale¿nie od ich faktycznie
potrzebnej liczby.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{images/schema_partitioning2.pdf}
  \caption{Przyk³ad podzia³u schematu na rodziny atrybutów}
\end{figure}

W celu rozwi±zania tego problemu zastosowano rozwi±zanie polegaj±ce na
grupowaniu atrybutów w tzw. \textit{rodziny} (\textit{column families}),
stosowane m.in. w bazie danych BigTable (oraz pochodnych, jak Cassandra czy
HBase). Przechowywana relacja dzielona jest na podrelacje, a te przechowywane
jako ci±gi stron (nazywane dalej \textit{rodzinami stron}) zorganizowanych na
wzór schematu PAX. Pozwala to zachowaæ do¶æ wysok± lokalno¶æ danych nale¿±cych
do pojedynczego wiersza, równocze¶nie umo¿liwiaj±c odczyt podzbiorów atrybutów z
warstwy fizycznej. \\

Warto jednak zauwa¿yæ, ¿e w przeciwieñstwie do BigTable podzia³ na rodziny jest
ca³kowicie transparentny dla wy¿szych warstw. We wspomnianych bazach musz± byæ
one explicite zdefiniowane przez u¿ytkownika i stanowi± czê¶æ schematu tabeli.
Czêsto nie ma te¿ mo¿liwo¶ci wykonywania zapytañ odnosz±cych siê do atrybutów z
ró¿nych rodzin. Omawiany magazyn nie narzuca takich ograniczeñ. Podzia³ odbywa
siê dynamicznie podczas zapisu i mo¿e byæ ró¿ny w ró¿nych plikach magazynu
przechowuj±cych tabele o identycznym schemacie. Podczas odczytu za¶,
podrelacje automatycznie z³±czane s± w relacjê wyj¶ciow±. \\

Koncepcjê grupowania atrybutów mo¿na rozszerzyæ, zmieniaj±c podzia³ schematu na
jego pokrycie - tzn. dopuszczaj±c wyst±pienie tego samego atrybutu w kilku
grupach. Redundancja taka z jednej strony zwiêksza objêto¶æ magazynu, a z
drugiej mo¿e dawaæ wiêksz± swobodê doboru rodzin w trakcie planowania odczytu i
w konsekwencji wiêksz± efektywno¶æ. Nie jest to jednak rozwi±zanie wspierane
przez opracowan± implementacjê. Id±c krok dalej mo¿na pokusiæ siê o oddzielnie
wektorów \texttt{IS\_NULL} (zawieraj±cych informacje o obecno¶ci danych) od
odpowiadaj±cych im kolumn, jest to jednak ma³o praktyczny pomys³ i w przypadku
omawianego magazynu s± one trzymane razem.


\subsection{Organizacja stron w pliku magazynu}

Plik magazynu sk³ada siê z ci±gu stron nale¿±cych do ró¿nych rodzin. W
ogólno¶ci, nie musi istnieæ zwi±zek miêdzy ich kolejno¶ci± wewn±trz pliku a
porz±dkiem wewn±trz przechowywanej tabeli. Na koñcu magazynu znajduje siê indeks
stron, bêd±cy s³ownikiem \texttt{(rodzina, strona) -> (pozycja\_w\_pliku,
rozmiar\_strony)}.  Umo¿liwia ona swobodny dostêp bezpo¶rednio do ¿±danych
stron, bez potrzeby przegl±dania ca³ego magazynu. \\

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/file_layout.pdf}
  \caption{Uk³ad stron w pliku}
\end{figure}

\subsection{Zapis}

Magazyn umo¿liwia zapis danych wy³±cznie na koñcu pliku i tylko do momentu jego
zamkniêcia. Jest on przeznaczony do pracy w hurtowniach danych, w których
potrzeba modyfikacji b±d¼ dodania do tablicy niewielkiej liczby rekordów jest
niezwykle rzadka. Ponadto, wielkie ilo¶ci danych czêsto przetwarzane s± w
¶rodowiskach rozproszonych, gdzie pliki wsadowe serwowane s± przez rozproszony
system plików. Te natomiast cechuje czêsto brak mo¿liwo¶ci zapisu losowego. W
momencie gdy modyfikacja danych jest konieczna, niezbêdne jest przeczytanie
istniej±cego magazynu i przepisanie danych do nowego. \\

Sam proces zapisu porcji wierszy mo¿na podzieliæ na trzy fazy:
\begin{itemize}
  \item{Podzia³ danych na podrelacje odpowiadaj±ce rodzinom atrybutów.}
  \item{Serializacjê danych i zesk³adowanie ich na stronie w schemacie PAX, w
obrêbie ka¿dej rodziny.}
  \item{Zapis wype³nionych stron danych do odpowiednich rodzin stron w pliku
magazynu (strona zostaje uznana za pe³n±, gdy jej rozmiar przekracza pewien
ustalony z góry zakres).}
\end{itemize}
Warto zauwa¿yæ, ¿e strony dla poszczególnych rodzin wype³niaj± siê z ró¿n±
prêdko¶ci± (zale¿n± od schematu podrelacji i zawarto¶ci wierszy). Oznacza to,
¿e w skrajnych przypadkach dane dotycz±ce wiersza mog± byæ znajdowaæ siê na
dwóch, przeciwnych koñcach pliku magazynu. Jednak¿e, dobieraj±c odpowiednio
rozmiar strony oraz podzia³ schematu na atrybuty, mo¿na zachowaæ dostatecznie
dobr± lokalno¶æ danych.

\subsubsection{Metadane}

Przy okazji zapisu stron danych dla relacji gromadzone s± nastêpuj±ce metadane:
\begin{itemize}
  \item{schemat ka¿dej rodziny atrybutów,}
  \item{liczba stron w ka¿dej rodzinie,}
  \item{liczba wierszy w ka¿dej stronie danych.}
\end{itemize}

Do ich zapisu wykorzystywana jest wyszczególniona rodzina stron (dla ustalenia
uwagi - powiedzmy, ¿e ma numer $0$), nie powi±zana z ¿adn± rodzin± atrybutów. W
momencie zamykania pliku magazynu, przed dodaniem indeksu stron, metadane
serializowane s± do postaci binarnej, a nastêpnie zapisywane w jedynej stronie
nale¿±cej do tej rodziny.

\subsection{Odczyt}

Plik magazynu umo¿liwia odczyt dowolnych stron nale¿±cych do dowolnych rodzin.
Odbywa siê to za po¶rednictwem opisywanego wcze¶niej indeksu. W celu poprawnej
interpretacji danych relacji wykorzystywane s± metadane, których logiczna
lokalizacja znana jest z góry (rodzina $0$, strona $0$). Maj±c do dyspozycji
schematy podrelacji dla ka¿dej z podrodzin mo¿na przyst±piæ do rekonstrukcji
danych tabeli. \\

Odczyt przebiega w nastêpuj±cy sposób:
\begin{itemize}
  \item{Dla ka¿dej rodziny atrybutów dane podrelacji s± rekonstruowane na
podstawie odpowiednich stron.}
  \item{Podrelacje s± z³±czane w wiêksz± ca³o¶æ, rekonstruuj±c pierwotn±
relacjê.}
\end{itemize}
Podobnie jak w przypadku zapisu, proces odczytu odbywa siê iteracyjnie,
dostarczaj±c kolejne porcje danych o ograniczonej liczby wierszy w celu ich
dalszego przetworzenia. Podrelacje nie s± rekonstruowane od razu w ca³o¶ci -
odczytana zostaje zawarto¶æ jedynie tylu stron ile niezbêdne jest do realizacji
pojedynczego kroku.

\subsubsection{Odczyt podzbioru atrybutów}

W przypadku gdy zapytanie odnosi siê wy³±cznie do niektórych kolumn tabeli,
mo¿liwe jest zlecenie odczytu wy³±cznie zadanego pozdbioru atrybutów relacji.
Powoduje to pominiêcie rodzin tych rodzin atrybutów, które nie dostarczaj±
¿adnej z ¿±danych kolumn, a co za tym idzie odczyt mniejszej ilo¶ci danych z
dysku. Efektywno¶æ tej techniki w g³ównej mierze zale¿y od podzia³u schematu na
rodzin.

\subsubsection{Odczyt danych od zadanego wiersza}

Dziêki zapisowi metadanych, mo¿liwy jest tak¿e efektywny odczyt danych od
zadanego wiersza. Maj±c wiedzê o liczby rekordów w ka¿dej stronie mo¿na z
³atwo¶ci± zidentyfikowaæ i pomin±æ te, które nie zawieraj± interesuj±cych
danych, a co za tym idzie zredukowaæ liczbê operacji wej¶cia/wyj¶cia do
niezbêdnego minimum.


\section{Architektura implementacji}

Poni¿sze opisy prezentuj± g³ówne klasy implementacji magazynu. Poniewa¿ w
ca³o¶ci funkcjonowania sk³adu najwiêksze znaczenie maj± operacje odczytu i
zapisu, architektura przedstawiona jest z perspektywy przep³ywu danych w trakcie
ich wykonywania. Szczegó³owy opis konkretnych aspektów implementacji znajduje
siê w dalszej czê¶ci pracy.

\subsection{Schemat zapisu}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\textwidth]{images/write_overview.pdf}
  \caption{Ogólny schemat zapisu danych}
\end{figure}

\begin{itemize}
  \item{Schemat tabeli dzielony jest na rodziny przy pomocy strategii
reprezentowanej przez obiekt klasy \texttt{SchemaPartitioner}. Jest ona podawana
przez u¿ytkownika.}
  \item{Do zapisu danych tworzona jest instancja klasy \texttt{StorageSink}
implementuj±cej interfejs \texttt{Sink} wykonawcy \textit{Supersonic}, który
reprezentuje uj¶cia danych. Udostêpnia od metodê \texttt{Write}, która przyjmuje
za argument widok zawieraj±cy porcjê danych.}
  \item{Równolegle utworzony zostaje obiekt klasy \texttt{MetadataWriter}.
Posiada on informacje na temat wydzielonych \textit{rodzin atrybutów} i
agreguje metadane dotycz±ce zapisywanych stron danych.}
  \item{Dane przekazywane do uj¶cia rozdzielane s± pomiêdzy obiekty klasy
\texttt{PageSink}. Ka¿dy z nich odpowiada za jedn±, wybran± \textit{rodzinê
stron} i zna jej numer. Dane odpowiednich atrybutów s± serializowane na strony
danych.}
  \item{Klasa \texttt{PageStreamWriter} udostêpnia interfejs umo¿liwiaj±cy zapis
logicznych stron do plików z warstwy fizycznej. Jest ¶wiadoma istnienia
\textit{rodzin stron} i buduje wewnêtrzny indeks, który umo¿liwi dostêp do
wybranych danych w trakcie odczytu.}
  \item{W momencie, gdy rozmiar strony wype³nianej przez \texttt{PageSink}
przekroczy zadany limit, zostaje one zapisana do strumienia reprezentowanego
przez obiekt klasy \texttt{PageStreamWriter}. Metadane dotycz±ce strony
przekazywane s± do instancji \texttt{MetadataWriter}, a \texttt{PageSink}
tworzy now± stronê dla dalszych zapisów.}
  \item{Po wyczerpaniu siê danych, \texttt{PageSink} zostaje zamkniêty przy
u¿yciu metody \texttt{Finalize}. W efekcie:
  \begin{itemize}
    \item{instancje \texttt{PageSink} zapisuj± wszystkie aktualnie tworzone
  strony danych do strumienia,}
    \item{\texttt{MetadataWriter} serializuje zagregowane informacje i równie¿
  zapisuje w strumieniu, do wyszczególnionej \textit{rodziny stron}
  (oczywi¶cie, nie przypisanej do ¿adnej \textit{rodziny atrybutów})}
    \item{Na sam koniec, \texttt{PageStreamWriter} zapisuje do pliku indeks
  stron oraz \textit{pieczêæ}. Pieczêæ pozwala na wczesne wykrycie
  uszkodzonych plików magazynu, nie nadaj±cych siê do odczut.}
  \end{itemize}
}
\end{itemize}


\subsection{Schemat odczytu}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/read_overview.pdf}
  \caption{Ogólny schemat odczytu danych}
\end{figure}

\begin{itemize}
  \item{Odczyt danych z pliku mo¿liwy jest przy u¿yciu interfejsu
\texttt{RandomPageReader}. Pozwala on na wydajny, swodobny dostêp do wybranych
stron danych, z konkretnych rodzin stron. Wykorzystuje do tego indeks budowany
przez obiekt klasy \texttt{PageStreamWriter} w trakcie zapisu.}
  \item{Dostêp do metadanych oraz schematu tabeli przechowywanej w magazynie
mo¿liwy jest przy u¿yciu instancji klasy \texttt{DataStorage}. S³u¿y ona równie¿
do tworzenia kursorów - obiektów reprezentuj±cych strumieñ bloków danych w
obliczeniach wykonawcy Supersonic. Kursor mo¿e pobieraæ dane dla wybranego
podzbioru atrybutów oraz od zadanego wiersza.  Warto przy okazji zaznaczyæ, ¿e
dostêp do metadanych poprzez \texttt{DataStorage} nie wi±¿e siê z odczytem
faktycznych danych tabeli. Umo¿liwia to ich wydajn±, statyczn± analizê np. przez
optymalizator zapytañ.}
  \item{Dane relacji ze stron udostêpnianych przez \texttt{RandomPageReader}
odczytywane s± przez obiekty \texttt{PageReader}. Ka¿dy z nich dostarcza
strumieñ bloków z danymi dok³adnie jednej rodziny atrybutów, deserializuj±c je z
odpowiednich stron. Poniewa¿ \texttt{PageReader} implementuje interfejs
kursora, mo¿na o nim my¶leæ jak o pe³nowarto¶ciowej operacji odczytu
pojedynczej podrelacji tabeli.}
  \item{Kursory dla pojedynczych rodzin atrybutów z³±czane s± w jeden, wiêkszy,
za pomoc± wbudowanej w Supersonica operacji \texttt{Coalesce}. Jej semantyka
odpowiada z³±czeniu tablic przy u¿yciu sztucznie wprowadzonego atrytutu
zawieraj±cego numer wiersza w strumieniu danych.}
\end{itemize}


\section{Szczegó³y implementacji}

\subsection{Podzia³ schematu na rodziny}

W opisywanej implementacji podzia³ schematu na rodziny odbywa siê przy pomocy
zadanej przez u¿ytkownika stretegii, reprezentowanej przez interfejs
\texttt{SchemaPartitioner}. Jako przyk³ad zaimplementowano trywialn± strategiê
\texttt{FixedSizeSchemaPartitioner}, polegajac± na podziale schematu tabeli na
grupy zawieraj±ce narzucon± z góry liczbê atrybutów (za wyj±tkiem ostatniej).  W
zasadzie nie istniej± ¿adne ograniczenia dotycz±ce metody podzia³u. W
szczególno¶ci, kolejno¶æ atrybutów w wynikowych grupach nie musi byæ w ¿aden
sposób powi±zana z kolejno¶ci± atrybutów w pierwotnym schemacie. Strategia
zwracaj±ca pojedyncz± grupê z permutacj± wszystkich kolumn jest poprawn± (choæ
raczej ma³o u¿yteczn±) strategi±. \\

Dobór odpowiedniego podzia³u schematu jest zagadnieniem bardzo ciekawym i mo¿e
mieæ istotny wp³yw na efektywno¶æ magazynu. Wczytuj±ce dane mo¿emy pobraæ strony
reprezentuj±ce tylko wybrane rodzin atrybutów. Nie da siê jednak dostaæ do
wybranego atrybutu nie wczytuj±c kompletnej strony, a co za tym idzie innych
atrybutów nale¿acych do jego rodziny. W konsekwencji, w zale¿no¶ci od podzia³u
ten sam pozdbiór kolumn mo¿e wymagaæ do odczytu diametrialnie ró¿nej liczb± 
operacji wej¶cia/wyj¶cia. Mo¿na wiêc próbowaæ optymalizowaæ koszt korzystania z
magazynu np. przez grupowanie atrybutów, które czêsto razem wystêpuj± w
zapytaniach\cite{column-vs-row}. Jest to jednak problem nietrywialny i móg³by z
powodzeniem stanowiæ temat samodzielnej pracy naukowej.


\subsection{Fizyczny uk³ad stron danych i plików}

\subsubsection{Organizacja strony}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/page_layout.pdf}
  \caption{Uk³ad danych na stronie}
\end{figure}

Strona danych jest obiektem wy³±cznie do odczytu, przechowuj±cym pewn± liczbê 
buforów danych o ró¿nych d³ugo¶ciach. Sk³adaj± siê z nastêpuj±cych czêsci:
\begin{itemize}
  \item{\textbf{nag³ówek strony} - zawieraj±cy informacje o jej rozmiarze oraz
liczbie przechowywanych buforów,}
  \item{\textbf{tablicê wska¼ników na bufory} - okre¶laj±ce pozycjê
poszczególnych buforów w obrêbie strony,}
  \item{\textbf{nag³ówki buforów} - zawieraj± informacje o rozmiarze buforu; w
przysz³o¶ci mog± zawieraæ informacje np. o zastosowanej kompresji,}
  \item{\textbf{dane buforów} - czyli ci±gi bajtów.}
\end{itemize}

Do tworzenia stron s³u¿± obiekty klasy \texttt{PageBuilder}. Umo¿liwiaj± one
dopisywanie danych na koñcu wybranych buforów oraz wyprodukowanie strony
zawieraj±cej wszystkie zgromadzone do tej pory dane. Potrafi± tak¿e w wydajny
sposób okre¶liæ rozmiar takiej strony bez potrzeby jej materializacji. \\

\subsection{Plik magazynu}

Plik magazynu sk³ada siê z dwóch g³ównych czê¶ci: ci±gu stron danych nale¿±cych
do ró¿nych rodzin oraz ich indeksu. Rysunek \ref{figure:page_index} przedstawia
sposób w jaki przechowywany jest indeks. Pierwsze cztery bajty zajmuje liczba
ró¿nych rodzin w magazynie. Nastêpnie, dla ka¿dej z rodzin, zapisany jest jej
numer, liczba stron oraz ich kolejne pozycje w obrêbie pliku oraz rozmiary
(strony zawsze maj± ci±g³± numeracjê, pocz±wszy od zera). \\

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\textwidth]{images/page_index.pdf}
  \caption{Organizacja indeksu stron na dysku}
  \label{figure:page_index}
\end{figure}

Otwarcie magazynu wi±¿e siê z wczytaniem i deserializacj± indeksu - bez niego 
niemo¿liwy jest efektywny dostêp do przechowywanych stron. Jego po³o¿enie w
obrêbie pliku zapisane jest jako 64-bitowa liczba na pozycji
\texttt{rozmiar\_pliku - 16} (w bajtach). \\

Ostatnie osiem bajtów pliku stanowi \textbf{pieczêæ integralno¶ci}, bêd±ca pewn±
ustalon± z góry liczb±. Jej brak w pliku magazynu ¶wiadczy, ¿e nie zosta³ on
poprawnie zamkniêty i dane wewn±trz niego najprawodopodobniej nie nadaj± siê do
odczytu. Oczywi¶cie, obecno¶æ poprawnej pieczêci wcale nie gwarantuje
poprawno¶ci danych. Pomaga jednak odsiaæ wiêkszo¶æ przypadków przerwanych
zapisów. \\


\subsection{Zapis danych do stron}

Zapis danych do stron odbywa siê przy udziale instancji klasy
\texttt{PageSink}. Posiada ona w³asny \texttt{PageBuilder}, który wykorzystuje
do tworzenia stron. \texttt{PageSink} otrzymuje do zapisu zbiór wierszy z
odpowiedniej rodziny atrybutów w postaci klasy \texttt{View}, przechowuj±cej
dane w organizacji kolumnowej. Ka¿da kolumna zostaje dopisana w zserializowanej
postaci na koñcu odpowiedniego buforu. W momencie, gdy rozmiar budowanej strony
przekroczy zadany limit zostaje ona zamkniêta i zapisana do strumienia, a jej
metadane zapamiêtane w \texttt{MetadaneWriter}.

\subsubsection{Serializacja danych}

Sposób serializacji zale¿y od typu danych. Te, w obecnej implementacji, dziel±
siê na trzy grupy:
\begin{itemize}
  \item{\textbf{Typ logiczny}, czyli ci±g warto¶ci \texttt{prawda/fa³sz}.
Ka¿da porcja danych zapisywana jest jako sekwencja 4-bajtowych masek bitowych
poprzedzona liczb± zserializowanych warto¶ci. Jest to przy okazji przyk³ad
zastosowania lekkiej kompresji.}
  \item{\textbf{Typy liczbowe}, o sta³ej szeroko¶ci. Zapisywane s± bez ¿adnej
konwersji, jako zrzut surowych danych kolumny, poprzedzony liczb± 
zserializowanych warto¶ci. Obecnie nie wspier}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/string_arena.pdf}
  \caption{Serializacja typów o zmiennej d³ugo¶ci - schemat areny}
\end{figure}

  \item{\textbf{Typy zmiennej d³ugo¶ci}, czyli ci±gi znakowe i binarne.
Serializacja polega na zapisie w strukturze nazywanej
\textit{aren±}\cite{arena,arena-kernel}. Ma ona postaæ spójnego bloku
pamiêci, z którego przydzielaæ mo¿na mniejsze fragmenty. Od strony logicznej
mo¿na o niej my¶leæ jak o stercie w jêzykach niskiego poziomu. Dla ka¿dego ci±gu
przydzielany jest bufor odpowiedniej wielko¶ci, do którego kopiuje siê jego
zawarto¶æ. Przestrzeñ alokowane jest od pocz±tku bloku areny, natomiast od koñca
zapisywane s± informacje na temat rozmiaru i pozycji przydzielonych fragmentów.
Omawiana implementacja przechowuje wy³±cznie d³ugo¶ci ci±gów.  Licz±c sumê
prefiksow± mo¿na okre¶liæ dok³adn± pozycjê ka¿dego zaalokowanego fragmentu
areny. Warto zauwa¿yæ, ¿e utrudnia to dostêp do warto¶ci znajduj±cych siê w
¶rodku serializowanej porcji danych. Nie jest to jednak problem, poniewa¿ ze
swojej natury Supersonic nastawiony jest na przetwarzanie strumieniowe, a nie
swobodny dostêp do danych.}

\end{itemize}

W wykonawcy zapytañ \textit{Supersonic} kolumna reprezentowana jest przez wektor
danych oraz wektor warto¶ci logicznych opisuj±cy obecno¶æ danych (warto¶ci
\textit{NULL}). S± one traktowane jako niezale¿ne zbiory danych i zapisywane do
oddzielnych buforów strony. W miejsce nieobecnych warto¶ci zapisywane s±
przypadkowe dane, znajduj±ce siê w odpowiednich miejscach pamiêci. Ich zawarto¶æ
nie ma znaczenia, poniewa¿ jest ignorowana w trakcie obliczenia.  Wyj±tkiem s±
typy o zmiennej d³ugo¶ci, które zawieraj± wska¼niki do ci±gów bajtów. W celu
zachownia poprawno¶ci algorytmu serilizacji pozycje oznaczone jako \textit{NULL}
inicjalizowane s± pustym ci±giem.

\subsubsection{Rozmiar strony}

\texttt{PageSink} zawsze zapisuje do strony wszystkie dane otrzymane w
pojedynczym wywo³aniu metody \texttt{Write(const\& View)}. Oznacza to, ¿e
rozmiar generowanych stron danych jest nie mniejszy ni¿ zadany limit, lecz
wcale nie musi byæ bardzo bliski niego. Przekazanie kilkuset tysiêcy wierszy
bezpo¶rednio do uj¶cia danych mo¿e spowodowaæ powstanie bardzo du¿ych stron
danych, a w konsekwencji spadek wydajno¶ci w trakcie odczytu. Im mniejsze
pojedyncze porcje danych przekazywane do zapisu, tym stabilniejsze rozmiary
stron. Warto przy tym zaznaczyæ, ¿e w typowym zastosowaniu Supersonic
przetwarza dane w stosunkowo niewielkich porcjach, swobodnie mieszcz±cych siê w
pamiêci podrêcznej procesora. W zwi±zku z tym, rozmiar generowanych stron nie
powinien stanowiæ problemu.

\subsection{Granulacja odczytu danych}
\label{sec:read_granularity}

Operacja odczytu jest w gruncie rzeczy kompletnie dualna do zapisu. Z pliku
magazynu odczytywane s± odpowiednie strony danych, deserializowane do
podrelacji, które nastêpnie s± z³±czane i zwracane do u¿ytkownika. Co istotne,
liczba wierszy przekazywana do wywo³ania metody \texttt{Next} kursora
\texttt{StorageScan} okre¶la wy³±cznie maksymaln± liczbê rekordów wyniku.
Faktyczny rozmiar zwróconego widoku zale¿y od stanu buforów stron danych
poszczególnych rodzin. Strony wczytywane s± wy³±cznie w momencie gdy bufor
odpowiedniej rodziny jest pusty \texttt{Next} i to najwy¿ej raz dla ka¿dej
rodziny w obrêbie jednego wywo³ania. W szczególno¶ci, niezale¿nie od rozmiaru
¿±dania, niemo¿liwe jest uzyskanie wiêkszej liczby wierszy ni¿ zapisana w
obrêbie pojedynczej strony danych. 

 
\subsection{Metadane}

Do serializacji metadanych wykorzystywana jest biblioteka
\textit{ProtocolBuffer}\cite{protobuf}, opublikowana przez firme Google na
zasadach wolnego oprogramowania. Umo¿liwia ona kodowanie ustrukturalizowanych
danych do postaci binarnej w wydajny sposób. Definicje struktur da siê w wygodny
sposób rozszerzaæ. Dziêki temu istnieje mo¿liwo¶æ dodania nowych rodzajów
metadanych w przysz³o¶ci, przy zachowaniu wstecznej kompatybilno¶ci plików
magazynu. Postaæ binarna metadanych zapisywana jest do pojedynczej strony w
\textbf{rodzinie stron} o numerze \textbf{0}. Jest to specjalne rodzina stron,
nie powi±zana z ¿adn± rodzin± atrybutów.

\subsection{Warstwa fizyczna}

Z perspektywy warstwy fizycznej, zapis odbywa siê do jednego b±d¼ wiêcej
plików. Zapis do serii plików jest szczególnie przydatny w przypadku
rozproszonych ¶rodowisk, w których istnieje wiele wêz³ów równolegle
przetwarzaj±cych dane tablicy. Podzia³ danych na pliki odbywa siê na podstawie
rozmiaru zapisanych danych - po przekroczeniu zadanego z góry limitu magazyn
zostaje zamkniêty i otwierany jest nowy. Utworzone pliki s± pe³nowarto¶ciowymi,
niezale¿nymi od siebie sk³adami danych. \\

Grupê plików w trakcie procesu zapisu i odczytu reprezentuje interfejs
\texttt{FileSeries}. Definiuje on iterator po nazwach ci±gu plików. Ci±g taki
nie musi byæ nieskoñczony (co jest przydatne w trakcie zapisu). Jako przyk³ad
zaimplementowano klasê \texttt{EnumeratedFileSeries}, generuj±ca nazwy na
podstawie zadanego ci±gu znaków z numerycznym sufiksem, np. \texttt{\{data.0,
data.2, data.3, ... \}}. \\

Wszystkie pliki serii powinny przechowywaæ ten sam zbiór atrybutów. Nie istniej±
natomiast wiêzy dotycz±ce podzia³u schematu na rodziny - mo¿e on byæ kompletnie
ró¿ny w ró¿nych plikach. Bywa to przydatne w przypadku przetwarzania danych
pochodz±cych z ró¿nych okresów, które (z ró¿nych wzglêdów) zapisywane by³y z
u¿yciem ró¿nych strategii.

\subsubsection{Abstrakcja plików}

Do operacji na plikach wykorzystywany jest interfejs \texttt{File},
udostêpniaj±cy podstawowe operacje dotycz±ce odczytu, zapisu, manipulacji
pozycj± w strumieniu oraz ¶cie¿ek. Supersonic dostarcza implementacjê dla
systemu plików zgodnych ze standardem POSIX. \\

Tworz±c w³asn± implementacjê \texttt{File} mo¿na dodaæ do magazynu obs³ugê w
zasadzie jakiegokolwiek medium. W praktyce interesuj±ce s± przede wszystkim
ró¿nego rodzaju rozproszone systemy plików, jak np. coraz czê¶ciej stosowany
\textit{HDFS}, u³atwiaj±ce równoleg³e przetwarzanie danych. Co istotne, nie
jest wymagane by dostarczona implementacja w stu procentach spe³nia³a interfejs
\texttt{File}. Dok³adniej rzecz bior±c, nie jest wymagana obs³uga zapisów w
¶rodku pliku - wystarczy mo¿liwo¶æ dopisywania nowych na koñcu. Brak
efektywnego mechanizmu modyfikacji fragmentu pliku jest czêst± cech± w
rozproszonych systemach plików. Na szczê¶cie, zarówno Supersonic jak i omawiany
magazyn danych, nastawione s± do pracy w ¶rodowisku, w którym nie modyfikuje
siê jednostkowych rekordów, a raczej zapisuje du¿e ilo¶ci przetworzonych danych
jako nowe tabele.


%
% Ewaluacja
%
\chapter{Ewaluacja}

\section{Platforma testowa}

Jako platformy testowej u¿yto dwóch komputerów o nastêpuj±cych parametrach:

\begin{itemize}
  \item{\textbf{Procesor}: Intel Core i7-3517U 1.9\ GHz (zablokowany na 3.0\ GHz
w trybie turbo)}
  \item{\textbf{Pamiêæ RAM}: 10\ GB DDR3 1600\ MHz (w dwóch ko¶ciach - 2\ GB oraz
8\ GB)}
  \item{\textbf{Dysk SSD} - Samsung 840 EVO 256\ GB SATA3 (przechowuj±cy równie¿
system operacyjny)}
  \item{\textbf{System operacyjny}: Ubuntu 12.04.4 LTS}
\end{itemize}
oraz
\begin{itemize}
  \item{\textbf{Procesor}: Intel Core i5-2500k 3.3 GHz (wy³±czone skalowanie
zegara)}
  \item{\textbf{Pamiêæ RAM}: 8\ GB DDR3 1600\ MHz (w dwóch ko¶ciach po 4\ GB)}
  \item{\textbf{Dysk HDD} - SAMSUNG Spinpoint F1 HD753LJ 750GB 7200 RPM 32MB
Cache SATA3 (bez systemu operacyjnego)} 
  \item{\textbf{System operacyjny}: Ubuntu 14.04.1 LTS}
\end{itemize}

W eksperymentach wykorzystano prost± implementacjê warstwy fizycznej
umo¿liwiaj±c± zapis do plików zgodny ze standardem POSIX. Jest ona w pe³ni
synchronicza i nie korzysta z bardziej zaawansowanych technik takich jak np.
\textit{odczyt z wyprzedzeniem} (\textit{read-ahead}), które mog± znacz±co
poprawiæ wydajno¶æ.

\subsubsection{Dane testowe}

W eksperymentach zosta³a wykorzystana tablica \textit{LINEITEM} pochodz±ca z
testu porównawczego \textit{TPC-H} (w wersji 2.17.0). Posiada ona 16 kolumn o
typach liczbowych i znakowych. Ze wzglêdu na brak dok³adnych odpowiedników w
Supersonicu, sta³oprzecinkowy typ \textit{DECIMAL} przedstawiony zosta³ jako typ
\textit{FLOAT}, natomiast ci±gi znaków sta³ej d³ugo¶ci \textit{VARCHAR} jako
normalne ci±gi znaków \textit{STRING}. \\

Przy generowaniu danych za pomoc± u¿yto wspó³czynnika skalowania $s = 4$. W efekcie
uzyskano relacjê zawieraj±c± 23'996'604 rekordów, zajmuj±cych w formie tekstowej
2942\ MB przestrzeni dyskowej.

\section{Testy zapisu}

Test polega³ na zapisie uprzednio wczytanej do pamiêci relacji do plików
magazynu o rozmiarze oko³o 128\ MB, zawieraj±cych strony danych o rozmiarze
minimum 512\ KB. Próby przeprowadzone zosta³y z ró¿nymi ustawieniami:
\begin{itemize}
  \item{maksymalnego rozmiaru pojedynczej rodziny: $1$, $2$, $4$, $8$, $16$
atrybutów;}
  \item{liczba wierszy przekazywanej do pojedynczego wywo³ania
\texttt{StorageSink::Write}: $500$, $1000$, $2000$, $3000$, $4000$, $5000$,
$6000$, $7000$, $8000$, $9000$, $10000$}
\end{itemize}
Czas mierzony by³ od momentu rozpoczêcia faktycznego zapisu, przy w³±czonej
pamiêci podrêcznej systemu plików, z wymuszeniem synchronizacji z no¶nikiem
danych na koñcu testu (za pomoc± funkcji systemowej \texttt{sync}). Ka¿dy test
wykonany zosta³ trzykrotnie. Prezentowane wyniki s± u¶rednione. Pomiêdzy
kolejnymi próbami czyszczona by³a pamiêæ podrêczna systemu plików. \\

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/write_throughput_hdd.pdf}
  \caption{Dysk HDD. Przepustowo¶æ operacji zapisu w zale¿no¶ci od rozmiaru rodziny i
wielko¶ci kroku zapisu.}
  \label{figure:write_throughput_hdd}
\end{figure}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/blocks.pdf}
  \caption{Liczba stron danych w magazynie w zale¿no¶ci od rozmiaru rodziny i
wielko¶ci kroku zapisu.}
  \label{figure:data_pages}
\end{figure}

Rysunek \ref{figure:write_throughput_hdd} przedstawia przepustowo¶æ operacji
zapisu, dla dysku talerzowego, w zale¿no¶ci od ustawieñ testu.  O¶ $Z$ zosta³a
przesuniêta w celu zwiêkszenia czytelno¶ci. Wydaje siê istnieæ niewielka
korelacja miêdzy przepustowo¶ci± a obiema ze zmiennych. Mo¿na podejrzewaæ,
¿e jest to zwi±zane z liczb± stron w magazynie jednak na podstawie rysunku
\ref{figure:data_pages} trudno jednoznacznie potwierdziæ tak± zale¿no¶æ. Faktem
natomiast jest, ¿e w zale¿no¶ci od ustawieñ, wydajno¶æ zapisu waha siê o 15-20\%.\\

Sam kszta³t wykresu liczby stron danych nie powinien dziwiæ je¶li pamiêta siê o
niepodzielno¶ci grup rekordów przekazywanych do zapisu. Im wiêkszy krok oraz
maksymalny rozmiar rodziny atrybutów, tym wiêkszy potencjalny rozmiar stron. Im
za¶ wiêksze strony tym mniej ich potrzeba do zapisu tej samej ilo¶ci danych. \\

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/write_throughput_ssd.pdf}
  \caption{Dysk SSD. Przepustowo¶æ operacji zapisu w zale¿no¶ci od rozmiaru rodziny i
wielko¶ci kroku zapisu.}
  \label{figure:write_throughput_ssd}
\end{figure}

W przypadku SSD w zasadzie brak jakiejkolwiek regularno¶ci w wynikach, za
wyj±tkiem faktu, ¿e wszystkie osculuj± w okolicach 180 MB/s. Wyniki
pojedynczych testów cechowa³a spora warinacja (20-30 MB/s). Byæ mo¿e da³oby siê
je bardziej ustabilizowaæ, przez u¿ycie wiêkszego zbioru danych. \\

W obu przypadkach wahania przepustowo¶ci operacji zapisu wynosz± 15-20\%. Bior±c
pod uwagê drugorzêdn± rolê operacji zapisu w funkcjonowaniu projektowanego
sk³adu jest to ró¿nica ma³o istotna. Sama prêdko¶æ w obu przypadkach wynosi
60-75\% maksymalnej prêdko¶ci zapisu sekwencyjnego no¶ników (oko³o 280 MB/s w
przypadku SSD, 60 MB/s HDD).  Nie jest to mo¿e wynik osza³amiaj±cy, ale w tym
przypadku ca³kowicie satysfakcjonuj±cy. \\

\section{Testy odczytu}

Je¶li nie napisano inaczej, w testach odczytu u¿yty zosta³ magazyn zapisany przy
u¿yciu nastêpuj±cych ustawieñ:
\begin{itemize}
  \item{pliki o rozmiarze oko³o 128 MB,}
  \item{strony danych rozmiaru oko³o 512 KB,}
  \item{rodziny	zawieraj±ce po dwa atrybuty,}
  \item{4000 rekordów zapisywanych w jednym kroku.}
\end{itemize}

Podobnie jak w przypadku zapisu, ka¿d± próbê przeprowadzono trzykrotnie a wyniki
u¶redniono. Pomiêdzy testami opró¿niano pamiêæ podrêczn± systemu plików.

\subsection{Przepustowo¶æ}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/read_throughput_hdd.pdf}
  \caption{Dysk HDD. Przepustowo¶æ operacji odczytu w zale¿no¶ci od rozmiaru rodziny i
wielko¶ci kroku odczytu.}
  \label{figure:read_throughput_hdd}
\end{figure}

Rysunki \ref{figure:read_throughput_hdd} oraz \ref{figure:read_throughput_ssd}
przedstawiaj± przepustowo¶æ operacji odczytu w zale¿no¶ci od maksymalnego
rozmiaru rodziny w odczytywanym magazynie oraz ¿±danej liczby wierszy w
pojedynczym wywo³aniu metody \texttt{Next} kursora \texttt{StorageScan}.  W obu
przypadkach mo¿na zaobserwowaæ nastêpuj±c± zale¿no¶æ:
\begin{enumerate}
  \item{Magazyny z podzia³em na rodziny rozmiaru 1 i 8 s± czytane szybciej ni¿
te z podzia³em na rodziny rozmiaru 2 i 4 (przy czym ró¿nice te s± znacznie
bardziej widoczne w przypadku HDD).}
  \item{Magazyn bez podzia³u na rodziny jest czytany istotnie szybciej ni¿
wszystkie inne.}
\end{enumerate}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/read_throughput_ssd.pdf}
  \caption{Dysk SSD. Przepustowo¶æ operacji odczytu w zale¿no¶ci od rozmiaru rodziny i
wielko¶ci kroku odczytu.}
  \label{figure:read_throughput_ssd}
\end{figure}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{images/seeks.pdf}
  \caption{Liczba operacji \textit{seek} w zale¿no¶ci od rozmiaru rodziny.}
  \label{figure:read_seeks}
\end{figure}

Zachowanie to mo¿na wynika najprawdpodobniej z uk³adu stron danych w obrêbie
odczytywanych plików. Rysunek \ref{figure:read_seeks} ilustruje liczbê operacji
\texttt{seek} niezbêdnych do przeczytania testowanych magazynów. W przypadku 
magazynu z jedn± tylko rodzin± obserwujemy odczyt bardzo bliski sekwencyjnemu,
co znacznie poprawia efektywno¶æ. Z reszt± nie jest ju¿ tak ³atwo - co
prawda magazyn z pe³nym podzia³em wymaga mniejszej ilo¶ci przesuniêæ ni¿ 3
pozosta³e, jednak przypadek podzia³u na rodziny rozmiaru 8 wymaga ich najwiêcej
wcale nie bêd±c najwolniejszym! \\

Jednak¿e, zale¿no¶æ nr 1 sugeruje, ¿e mamy do czynienia z problemami zwi±zanymi
z losowym odczytem. Wynika to z faktu, ¿e obserwacja jest znacznie bardziej
wyra¼na w przypadku dysku talerzowego, który posiada mechaniczn± g³owicê. W
zwi±zku z tym, mo¿na s±dziæ, ¿e poza sam± liczb± przesuniêæ istotne jest w
jakie dok³adnie miejsce je przesuwamy (czyli dystans pokonywany przez g³owicê).
Byæ mo¿e w przypadku magazynu z podzia³em na rodziny rozmiaru 8 mieli¶my do
czynienia z wiêksz± liczb± operacji \textit{seek} lecz na mniejszy dystans.
Jest to jednak wy³±cznie hipoteza i powinna zostaæ sprawdzona dok³adniejszymi
testami. \\

Niestety, o ile w przypadku dysku SSD mo¿na mówiæ o istotnej przewadze prêdko¶ci
odczytu wzglêdem zapisu, to dla HDD nie jest ona a¿ tak wyra¼na i mie¶ci siê
zazwyczaj w 20\%. Mamy tu do czynienia z ukrytym potencja³em, który
przypuszczalnie da³oby siê wykorzystaæ stosuj±c bardziej wyszukane techniki
doboru rozmiaru stron danych i u³o¿enia ich w obrêbie fizycznego pliku.


\subsection{Odczyt od zadanego wiersza}
\label{sec:read_offset}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/read_offset_hdd.pdf}
  \caption{Dysk HDD. Czas odczytu w zale¿no¶ci od podzia³u na rodziny i czê¶ci
odczytywanych wierszy.}
  \label{figure:read_offset_hdd}
\end{figure}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/read_offset_ssd.pdf}
  \caption{Dysk SSD. Czas odczytu w zale¿no¶ci od podzia³u na rodziny i czê¶ci
odczytywanych wierszy.}
  \label{figure:read_offset_ssd}
\end{figure}

Test polega³ na odczycie danych z magazynu pocz±wszy od zadanego wiersza.
Rysunki \ref{figure:read_offset_hdd} oraz \ref{figure:read_offset_ssd} ukazuj±
zale¿no¶æ miêdzy czasem trwania operacji a czê¶ci± danych, któr± nale¿a³o
odczytaæ, dla magazynów zapisanych z ró¿nymi ustawieniami podzia³u atrybutów na
rodziny. Jest tu doskonale widoczna korzy¶æ p³yn±ca z przechowywania metadanych
dotycz±cych stron - niepotrzebne dane zostaj± pominiête w trakcie odczytu z
warstwy fizycznej, co w przeka³ada siê na wprost proporcjonalny spadek czasu
realizacji ¿±dania. Typ no¶nika nie ma w zasadzie ¿adnego, istotnego wp³ywu,
podobnie jak sposób podzia³u na rodziny. \\

Warto zauwa¿yæ, ¿e zachowanie takie jest mo¿liwe dziêki niewielkiemu stosunkowi
rozmiaru stron danych wzglêdem rozmiaru ca³ego magazynu. Gdyby zwiêkszyæ
rozdzielczo¶æ przedstawionych wykresów, okaza³oby siê, ¿e w istocie s± one
schodkowe. Rozmiar stopnia zale¿y za¶ w³a¶nie od wzglêdnego rozmiaru strony, co
w tym konkretnym przypadku testowym oznacza dok³adno¶æ pominiêcia rekordów na
poziomie kilku promili.


\subsection{Odczytu podzbioru atrybutów}
\label{sec:read_subset}

W celu zbadania jak magazyn reaguje na ¿±dania dostarczenia podzbioru atrybutów
relacji wykorzystane zosta³y zapytania pochodz±ce z \textit{TPC-H}. Dla ka¿dego
z zapytañ wybrane zosta³y kolumny tabeli \texttt{LINEITEM} bior±ce w nim czynny
udzia³, a nastêpnie zlecone do odczytania z magazynu. Zapytania nie maj±ce do
czynienia z tablic± \texttt{LINEITEM} zosta³y pominiête.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\textwidth]{images/read_queries_hdd.pdf}
  \caption{Dysk HDD. Czas odczytu w zale¿no¶ci od zapytania.}
  \label{figure:read_queries_hdd}
\end{figure}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\textwidth]{images/read_queries_ssd.pdf}
  \caption{Dysk SSD. Czas odczytu w zale¿no¶ci od zapytania.}
  \label{figure:read_queries_ssd}
\end{figure}

Rysunki \ref{figure:read_queries_hdd} oraz \ref{figure:read_queries_ssd}
przedstawiaj± otrzymane wyniki. Widaæ na nich wyra¼nie, ¿e dane odczytywane s±
ca³ymi rodzinami. Oszczêdno¶æ czasu jest proporcjonalna do liczby rodzin jakie
mo¿na pomin±æ.

\section{Testy porównawcze}

Omawiany magazyn zosta³ porównany z dwoma popularnymi systemami bazodanowymi:
\textit{MySQL} (w wersji 5.5, mechanizm sk³adowania danych \textit{InnoDB}) oraz
\textit{PostgreSQL} (w wersji 9.1). Na obu wykonano testy analogiczne do
opisanych w sekcjach \ref{sec:read_offset} oraz \ref{sec:read_subset}. Nale¿y
tu zaznaczyæ, ¿e systemy te nie by³y tworzone z my¶l± o pracy w hurtowni
danych, a raczej ¶rodowiskach OLTP. Autor usi³owa³ dokonaæ porównania z
kolumnowymi bazami danych \textit{MonetDB} oraz \textit{Infobright}. Niestety,
nie uda³o siê uzyskaæ ¿adnych miarodajnych wyników. Nie istnia³ prosty sposób
odwo³ywania siê bezpo¶rednio do warstwy magazynowania danych, natomiast podczas
wykonywania zapytañ wykorzystywa³y one ró¿nego rodzaju techniki optymalizacyjne
(mapowanie danych w pamiêæ RAM, posi³kowanie siê szerok± gam± metadanych,
wstêpne ³adowanie danych do pamiêci podrêcznej itd.) zaciemniaj±ce obraz
sytuacjisiê uzyskaæ ¿adnych miarodajnych wyników. Nie istnia³ prosty
sposób odwo³ywania siê bezpo¶rednio do warstwy magazynowania danych, natomiast
podczas wykonywania zapytañ wykorzystywa³y one ró¿nego rodzaju techniki
optymalizacyjne (mapowanie danych w pamiêæ RAM, posi³kowanie siê szerok± gam±
metadanych,.

\subsection{Odczyt podzbioru atrybutów}
Niestety, wspomniane systemy nie udostêpniaj± prostej metody bezpo¶redniego
dostêpu do magazynu danych. Z tego powodu, w trakcie testu wykonywane by³y
zapytania postaci: \\

  \texttt{SELECT COUNT(A1), ... , COUNT(An) FROM LINEITEM} \\

gdzie $A_1, ..., A_n$ to zbiór wymaganych atrybutów. Zapytania takie wymuszaj±
wczytanie zawarto¶ci podanych kolumn, generuj±c przy tym mo¿liwie minimalny narzut
czasowy zwi±zany z samym obliczeniem. Dziêki temu czas ich wykonania powinien
byæ bardzo bliski faktycznemu czasowi samego odczytu, a przez to mo¿liwy do
porównanie z wynikami testu opisywanego magazynu. \\

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\textwidth]{images/compare_queries.pdf}
  \caption{Zestawienie czasu wykonania zapytañ o podzbiór atrybutów.}
  \label{figure:compare_queries}
\end{figure}

Rysunek \ref{figure:compare_queries} przedstawia zestawienie czasu wykonania
testów polegaj±cych na pobraniu wymaganego podzbioru, tak jak zosta³o to
opisane w sekcji \ref{sec:read_subset}. Widaæ na nim wyra¼nie, ¿e zarówno
\textit{MySQL} jak i \textit{PostgreSQL} pobieraj± z dysku komplet danych. Czas
wykonania jest co prawda zkorelowany z ilo¶ci± atrybutów, lecz ró¿nice s±
bardzo ma³e. Sugeruje to, ¿e istniej± one na poziomie przetwarzania danych
przez procesor, nie komunikacji ze sk³adem danych. Omawiany w pracy magazyn w
ka¿dym przypadku jest szybszy, czasami nawet o rz±d wielko¶ci.


\subsection{Odczyt od zadanego wiersza}

W celu przetestowania odczytu danych od wybranego wiersza na tabeli za³o¿ony
zosta³ klucz g³ówny (z³o¿ony z kolumn \texttt{L\_ORDERKEY} oraz
\texttt{L\_LINENUMBER}), po którym fizycznie posortowano rekordy (w bazie
\texttt{PostgreSQL} klucz g³ówny nie implikuje porz±dku danych na dysku). Na
tak spreparowanej relacji wykonywano zapytania nastêpuj±cej postaci: \\

  \texttt{SELECT COUNT(A1), ... , COUNT(An) FROM LINEITEM WHERE L\_ORDERKEY >= X} \\

Gdzie \texttt{X} by³ uprzednio wyliczonym numerem gwarantuj±cy odpowiedni±
selektywno¶æ zapytania. W za³o¿eniu - dostêpno¶æ indeksu na kluczu którego
wykonujemy zapytanie o przedzia³ oraz odpowiadaj±cy mu porz±dek na dysku,
powinny wystarczyæ systemowi bazodanowemu do efektywnej obs³ugi takie ¿±dania.
Jednak¿e, korzystanie z indeksu samo w sobie nie jest operacj± darmow± i baza
mo¿e zadecydowaæ, ¿e wykonanie pe³nego skanu tablicy jest bardziej op³acalne.
¯eby tego unikn±æ (wyniki wygl±da³yby wtedy jak z rysunku
\ref{figure:compare_queries} dla \texttt{Q4}) korzystanie z indeksu zosta³o
wymuszone rêcznie (odpowiednio przez komendy \texttt{FORCE INDEX} oraz
\texttt{enable\_seqscan=false}). \\

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\textwidth]{images/compare_offsets.pdf}
  \caption{Zestawienie czasu wykonania zapytañ o ci±g³y przedzia³ wierszy.}
  \label{figure:compare_offsets}
\end{figure}

Rysunek \ref{figure:compare_offsets} pokazuje wyniki eksperymentów. W przypadku
\textit{MySQL} wystêpuj± nieznaczne ró¿nice pomiêdzy kolejnymi testami (na
poziomie 700ms), które bardzo trudno zauwa¿yæ na wykresie. Generalnie jednak
czas wykonania jest mniej wiêcej niezale¿ny od rozmiaru niezbêdnych danych.
Nieco lepiej ma siê sprawa z baz± \textit{PostgreSQL}. Widaæ wyra¼ny, liniowy
spadek czasu obliczenia wraz z liczb± wierszy. Warto jednak zauwa¿yæ, ¿e dla
przypadków od 0.6 do 0.9, przy wykorzystaniu dysku HDD, bardziej op³aca siê
wykonaæ pe³ne skanowanie tablicy. Magazyn danych Supersonica wypada w tym
porównaniu bardzo dobrze.


\subsection{Rozmiar danych na no¶niku}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/storage_size.pdf}
  \caption{Zestawienie rozmiaru sk³adu w zale¿no¶ci od typu.}
  \label{figure:storage_size}
\end{figure}

Rysunek \ref{figure:storage_size} ukazuje ró¿nice w rozmiarach miêdzy
poszczególnymi rodzajami sk³adów. Reprezentacja tekstowa wygenerowana zosta³a
przez narzêdzia do³±czone do \textit{TPC-H} i zawiera kolumny rozdzielane
znakiem \texttt{|}. W przypadku MySQL oraz PostgreSQL rozmiar zosta³ pozyskany
poprez u¿ycie odpowiednich komend (odpowiednio \texttt{SHOW TABLE STATUS} oraz
\texttt{SELECT pg\_table\_size(lineitem)}). Tablice zapisane zosta³y bez
redundancji. \\

Ró¿nice s± tu bardzo wyra¼ne i dochodz± do 50\% na korzy¶æ omawianego sk³adu. W
stosunku do formatu tekstowego uzyskuje przewagê dziêki kolumnom liczbowym i
datom, które mie¶ci zawsze w czterech bajtach (plus jeden bit w wektorze
\texttt{IS\_NULL}). W przypadku MySQL oraz PostgreSQL ró¿nica wynika w du¿ej
mierze z obs³ugi operacji modyfikacji wierszy. W przypadku typów tekstowych
wymaga to rezerwacji dostatecznej ilo¶ci miejsca (¿eby unikn±æ ewentualnej
relokacji rekordu). W definicjach wygenerowanych przez \texttt{TPC-H}
wykorzystywany jest typ \texttt{VARCHAR} o pojemno¶ci równej najwiêkszej
warto¶ci w wybranej kolumnie. Wiêkszo¶æ danych jest jednak mniejsza (np. dla
kolumny \texttt{L\_COMMMENT} maksimum wynosi 44, natomiast ¶rednia 26.5) i w
efekcie znaczna czê¶æ przestrzeni nie jest wykorzystywana. 

%
% Podsumowanie
%
\chapter{Podsumowanie}

W dzisiajszych czasach problem efektywnego przetwarzania ogromnych zbiorów
danych, np. na potrzeby systemów wspomagania decyzji, nabiera coraz wiêkszego
znaczenia. Popularne, wierszowe bazy danych, przystosowane do pracy w
¶rodowiskach typu OLTP, nie s± w stanie zaspokoiæ tych potrzeb. W takich
warunkach du¿o lepiej sprawdzaj± siê systemy kolumnowego, które mimo istnienia
od przesz³o trzydziestu lat, nigdy nie szerokiego audytorium. \\

Supersonic jest przyk³adem nowoczesnego, kolumnowego wykonawcy zapytañ,
udostêpnionego na zasadach wolnego oprogramowania przez firmê \textit{Google}.
Dziêki ¶wiadomemu wykorzystaniu funkcji nowoczesnych procesorów jest on w stanie
uzyskaæ bardzo wysok± wydajno¶æ w ¶rodowiskach typowych dla hurtownii danych.
Niestety, trudno go w chwili obecnej nazwaæ pe³noprawnym systemem bazodanowych -
nie posiada on wielu oczekiwanych przez u¿ytkowników funkcjonalno¶ci, w tym
warstwy umo¿liwiaj±cej trwa³e magazynowanie przetwarzanych danych. \\

W niniejszej pracy zaprojektowano i zaimplementowano sk³ad danych dla wykonawcy 
zapytañ Supersonic. Wykorzystuje on fizyczn± organizacjê danych, bêd±c±
wariacj± na temat schematu \textit{PAX} oraz grupowania kolumn wystêpuj±cego np.
w bazie danych \textit{BigTable}. Dziêki temu mo¿liwy jest wydajny odczyt
podzbioru atrybutów, co jest czêst± operacj± w przypadku systemów wspieraj±cych
podejmowanie decyzji, gdzie tabele posiadaj± czêsto nawet kilkaset kolumn.
Dodatkowo, magazyn wspiera sk³adowanie metadanych i wykorzystuje je w celu
realizacji odczytów z pominiêciem zadanej ilo¶ci wierszy. Wykorzystanie
serializacji przy pomocy biblioteki \textit{ProtocolBuffers} umo¿liwia dodanie w
przysz³o¶ci nowych statystyk, które umo¿liwi± dodatkowe optymalizacje, z
zachowaniem kompatybilno¶ci wstecznej z wcze¶niejszymi wersjami sk³adu.
Architektura magazynu pozwala równie¿ na dostarczenie ró¿nych implementacji
warstwy fizycznej - pocz±wszy od zwyk³ych plików systemu operacyjnego, przez
rozwi±zania rozproszone, a¿ po dedykowane urz±dzenia, co powinno u³atwiæ
adaptacjê w nowych ¶rodowiskach. \\

Testy wydajno¶ci pokaza³y, ¿e w porównaniu z popularnymi, dojrza³ymi systemami
bazodanowymi, \textit{MySQL} oraz \textit{PostgreSQL}, opracowany magazyn bardzo
dobrze wykonuje stawiane przed nim zadania. Nale¿y jednak pamiêtaæ, ¿e
wymienione systemy by³y projektowane z my¶l± o ¶rodowiskach typu OLTP, w zwi±zku
z czym zestawienie takie nie jest w pe³ni miarodajne. Niestety, próba porównania
z istniej±cymi kolumnowymi bazami danych takimi jak \textit{MonetDB} oraz
\textit{Infobright} nie powiod³a siê, ze wzglêdu na trudno¶ci w zmierzeniu
faktycznego czasu dostêpu do ich sk³adów danych. Ponadto, testy wykaza³y
znaczenie fizycznego rozmieszczenia stron danych w obrêbie pliku, zw³aszcza w
przypadku dysków talerzowych. \\

Przedstawiony w pracy magazyn jest co prawda w pe³ni funkcjonalny, lecz tak
naprawdê stanowi jedynie bazê, na której zbudowaæ mo¿na bardziej skomplikowane
rozwi±zania. Spo¶ród tematów, które mog³yby byæ przedmiotem dalszych badañ
wymieniæ mo¿na: zastosowanie kompresji danych, zbieranie i wykorzystywanie
wiêkszej ilo¶ci statystyk czy optymalizacjê rozmiaru, u³o¿enia oraz odczytu
stron danych wewn±trz fizycznych plików. Cenne by³oby tak¿e przeprowadzenie
bardziej miarodajnych testów, zw³aszcza z systemami dedykowanymi do pracy w
hurtowniach danych.

%
% Bibliografia
%

\bibliographystyle{plain}
\bibliography{test}

\end{document}

